{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling Web Berita CNN Indonesia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apa itu Crawling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crawling merupakan proses search engine untuk menemukan konten atau sesuatu situs halaman yang ada. Dalam bahasa kerennya crawling atau web crawling merupakan proses dimana search engine mengirimkan bot atau robot yang disebut (crawler atau spider) yang digunakan untuk menemukan konten-konten yang ada.\n",
    "\n",
    "Yang dimaksud konten yaitu bervariasi, mulai dari halaman website yang saya lakukan ini, kemudian gambar, video, dokumen, dan lain sebagainya. Seperti halnya laba-laba, datang ke sebuah jaring dan melihat beberapa halaman website, kemudian mengikuti link yang terdapat di halaman website tersebut untuk mencari URL yang baru.\n",
    "\n",
    "Ketika ada pengguna yang mencari sebuah konten di search engine dengan keyword tertentu, search engine akan mencarinya di indeks dan menentukan konten mana yang paling sesuai untuk pengguna tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proses Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool atau Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library yang dibutuhkan\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Request** digunakan untuk mengambil html/http dari sebuah website.\n",
    "* **BeautifulSoup** berfungsi untuk mengambil data dari html/xml.\n",
    "* **Time** berfungsi untuk memberikan jeda ketika ingin berpindah halaman.\n",
    "* **Pandas** digunakan untuk membuat dataframe agar mudah dibaca.\n",
    "* **tqdm** Untuk mentracking proses program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fungsi Clean_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\ttext = text.replace('\\xa0', '',)\n",
    "\treturn text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi untuk membersihkan text yang tidak diinginkan, atau mengganggu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fungsi scrape_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_news(soup):\n",
    "\tberita = {}\n",
    "\ttexts = []\n",
    "\t# TODO:\n",
    "\t# ada struktur aneh https://www.cnnindonesia.com/olahraga/20240830134615-142-1139388/live-report-timnas-indonesia-vs-thailand-u-20\n",
    "\t\n",
    "\tberita[\"judul\"] = soup.title.text\n",
    "\n",
    "\ttext_list = soup.find(\"div\", class_=\"detail-text text-cnn_black text-sm grow min-w-0\")\n",
    "\tfor text in text_list.find_all(\"p\"):\n",
    "\t\tif 'para_caption' not in text.get('class', []):\n",
    "\t\t\tcleaned_text = clean_text(text.text)\n",
    "\t\t\ttexts.append(cleaned_text)\n",
    "\t\t\n",
    "\tberita[\"isi\"] = \"\\n\".join(texts)\n",
    "\tberita[\"tanggal\"] = soup.find(\"div\", class_=\"container !w-[1100px] overscroll-none\").find_all(\"div\")[1].find_all(\"div\")[4].text\n",
    "\tberita[\"kategori\"] = soup.find(\"a\", attrs={\"aria-label\": \"link description\", \"dtr-act\": \"kanal\"}).text\n",
    "\treturn berita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada fungsi ini berisikan proses pembedahan dan juga pengambilan data pada sebuah website. Mengambil data sesuai struktur HTML/web yang ingin diambil datanya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fungsi get_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "\ttry:\n",
    "\t\tresponse = req.get(url).text\n",
    "\t\treturn bs(response, \"html5lib\")\n",
    "\t\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\treturn \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi get_html dengan parameter url digunakan untuk mengambil response atau isi html dari web. Untuk mengambil response tersebut dibutuhkan library request, dan juga BeautifulSoup untuk mendapatkan isi html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fungsi get_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(soup):\n",
    "\tcontainer = soup.find(\"div\", class_=\"container !w-[1100px] overscroll-none\")\n",
    "\tnews_list = container.find_all(\"article\", class_=\"flex-grow\")\n",
    "\treturn news_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi get_news berfungsi untuk mengambil semua berita yang ada pada web, yang kemudian didapat kumpulan url berita yang ada pada halaman web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(halaman=1):\n",
    "\turl = [\"https://www.cnnindonesia.com/nasional/indeks/3/\", \"https://www.cnnindonesia.com/internasional/indeks/6/\"]\n",
    "\t# url = [\"https://www.cnnindonesia.com/internasional/indeks/6/\"]\n",
    "\tnews = []\n",
    "\tcount = 1 # - n\n",
    "\n",
    "\tfor _ in range(len(url)):\n",
    "\t\turl_now = url.pop()\n",
    "\t\tfor counter in range(halaman):\n",
    "\t\t\tpage = url_now + str(count)    \n",
    "\t\t\tsoup = get_html(page)\n",
    "\t\t\tnews_list = get_news(soup)\n",
    "\t\t\t\n",
    "\t\t\tfor item in tqdm(news_list, desc=f\"Processing page {count}\"):\n",
    "\t\t\t\tnews_url = item.find('a')['href']\n",
    "\t\t\t\t# print(news_url)\n",
    "\t\t\t\tsoup_news = get_html(news_url)\n",
    "\t\t\t\tresult = scrape_news(soup_news)\n",
    "\t\t\t\tnews.append(result)\n",
    "\t\t\tcount+=1\n",
    "\t\t\ttime.sleep(1)\n",
    "\t\t\n",
    "\treturn news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menyiapkan link/base url web berita yang ingin dicrawling, terdapat beberapa fungsi yang dipanggil yang sudah dibuat sebelumnya untuk mengambil informasi atau berita pada halaman website. Dalam code tersebut terdapat beberapa tahapan seperti fungsi:\n",
    "* get_html\n",
    "* get_news\n",
    "* scrape_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing page 1: 100%|██████████| 10/10 [00:03<00:00,  2.90it/s]\n",
      "Processing page 2: 100%|██████████| 10/10 [00:03<00:00,  2.98it/s]\n",
      "Processing page 3: 100%|██████████| 10/10 [00:03<00:00,  2.58it/s]\n",
      "Processing page 4: 100%|██████████| 10/10 [00:03<00:00,  2.57it/s]\n",
      "Processing page 5: 100%|██████████| 10/10 [00:03<00:00,  2.94it/s]\n",
      "Processing page 6: 100%|██████████| 10/10 [00:03<00:00,  2.91it/s]\n",
      "Processing page 7: 100%|██████████| 10/10 [00:03<00:00,  2.61it/s]\n",
      "Processing page 8: 100%|██████████| 10/10 [00:04<00:00,  2.48it/s]\n",
      "Processing page 9: 100%|██████████| 10/10 [00:04<00:00,  2.32it/s]\n",
      "Processing page 10: 100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# halaman = int(input('Crawling berapa Halaman? '))\n",
    "halaman = 5\n",
    "news = main(halaman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menjalankan program yang sudah dibuat dengan input berapa halaman yang ingin diambil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(news)\n",
    "df\n",
    "df.to_csv(\"data_100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presiden Rusia Vladimir Putinbergurau bahwa dirinya mendukung calon Presiden (capres) Amerika Serikat dari Partai Demokrat, Kamala Harris, alih-alih capres dari Partai Republik, Donald Trump.\n",
      "Putin berkelakar Harris memiliki tawa yang menular yang mencerminkan bahwa dunia baik-baik saja.\n",
      "\n",
      "\"Dia tertawa begitu ekspresif dan menular sehingga itu berarti semuanya baik-baik saja dengannya,\" kata Putin, seperti dikutip Reuters.\n",
      "Putin melontarkan candaan ini saat sedang menjawab pertanyaan moderator di acara forum ekonomi di Rusia pada Kamis (5/9). Sang moderator kala itu bertanya bagaimana pandangan Putin mengenai pemilihan umum di AS.\n",
      "Putin mulanya menjawab serius bahwa pemilihan umum di AS tergantung pada pilihan rakyat Amerika.\n",
      "Namun, dia berkelakar bahwa Presiden petahana Joe Biden saat ini mendukung Harris. Oleh sebab itu, dirinya pun akan memilih Harris.\n",
      "\"Kami akan melakukan hal yang sama, kami akan mendukungnya,\" kata Putin.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Awal tahun ini, Putin sempat berkomentar bahwa dirinya lebih memilih Biden dibandingkan Trump karena Biden lebih \"jadul\" sehingga mudah ditebak.\n",
      "Meski begitu, badan intelijen AS percaya Putin lebih setuju Trump memenangkan pemilihan presiden (pilpres) daripada Harris, sebab Trump tak begitu mendukung Ukraina dalam perangnya dengan Kremlin.\n"
     ]
    }
   ],
   "source": [
    "print(df['isi'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
